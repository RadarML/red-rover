# I/Q-1M: one million i/q frames

![CC BY License](https://img.shields.io/badge/license-CC%20BY-green)
![Roverd Data Format](https://img.shields.io/badge/data%20format-roverd-purple)

<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 5px;">
    <img src="images/iq1m-bike.jpg" alt="IQ1M Bike" style="width: 100%; min-width: 200px;">
    <img src="images/iq1m-indoor.jpg" alt="IQ1M Indoor" style="width: 100%; min-width: 200px;">
    <img src="images/iq1m-outdoor.jpg" alt="IQ1M Outdoor" style="width: 100%; min-width: 200px;">
</div>

!!! info

    We are currently working to prepare the dataset for public release and distribution. For the time being, please contact Tianshu Huang (<tianshu2@andrew.cmu.edu>) for access.

## Overview

The I/Q-1M dataset consists of 1M radar-lidar-camera samples[^1] over 29 hours across indoor, outdoor, and bike-mounted settings, each with a mobile observer:

- `indoor`: inside buildings at a slow to moderate walking pace, visiting multiple floors and areas within each.
- `outdoor`: neighborhoods ranging from single family detached to high density commercial zoning at a moderate to fast walking pace.
- `bike`: bike rides in different directions from a set starting point with a moderate biking pace.

!!! tip

    See our paper for more details about the dataset. Make sure to download the arxiv version to see the attached (and linked) appendix!

[^1]: The radar was collected at 20Hz, the Lidar at 10Hz, and the camera at 30Hz; as such, Lidar is limiting sensor to arrive at our 1M sample count.

| Setting | Size | Length | Average Speed | Max Doppler | Max Range |
|---------|------|--------|---------------|-------------|-----------|
| `indoor` | 310k | 8.9h | 1.0m/s | 1.2m/s | 11.2m |
| `outdoor` | 372k | 10.7h | 1.4m/s | 1.8m/s | 22.4m |
| `bike` | 333k | 9.3h | 5.4m/s | 8.0m/s | 22.4m |

## Index of Files

!!! tip

    See the [roverd](../roverd/index.md) documentation for details about the data format.

```
{sequence}
 â”£ ðŸ“‚_camera
 â”ƒ â”£ ðŸ“œmeta.json
 â”ƒ â”£ ðŸ“œpose.npz             # interpolated cartographer poses with camera timestamps
 â”ƒ â”£ ðŸ“œsegment              # lzma-compressed semantic segmentation class maps
 â”ƒ â”£ ðŸ“œsegment_i            # byte offsets
 â”ƒ â”— ðŸ“œts                   # camera timestamps (same as camera/ts)
 â”£ ðŸ“‚_lidar
 â”ƒ â”— ðŸ“œpose.npz             # cartographer poses with lidar timestamps
 â”£ ðŸ“‚_radar
 â”ƒ â”— ðŸ“œpose.npz             # cartographer poses with radar timestamps
 â”£ ðŸ“‚_slam
 â”ƒ â”— ðŸ“œtrajectory.csv       # raw cartographer output
 â”£ ðŸ“‚camera
 â”ƒ â”£ ðŸ“œmeta.json
 â”ƒ â”— ðŸ“œts                   # camera timestamps (30Hz)
 â”£ ðŸ“‚imu
 â”ƒ â”£ ðŸ“œacc                  # linear acceleration
 â”ƒ â”£ ðŸ“œavel                 # angular velocity
 â”ƒ â”£ ðŸ“œmeta.json
 â”ƒ â”£ ðŸ“œrot                  # rotation
 â”ƒ â”— ðŸ“œts                   # IMU timestamps (100Hz)
 â”£ ðŸ“‚lidar
 â”ƒ â”£ ðŸ“œlidar.json
 â”ƒ â”£ ðŸ“œmeta.json
 â”ƒ â”£ ðŸ“œnir                  # lzma-compressed near-infrared image
 â”ƒ â”£ ðŸ“œnir_i                # byte offsets
 â”ƒ â”£ ðŸ“œrfl                  # lzma-compressed IR reflectance
 â”ƒ â”£ ðŸ“œrfl_i                # byte offsets
 â”ƒ â”£ ðŸ“œrng                  # lzma-compressed beam-time depth map
 â”ƒ â”£ ðŸ“œrng_i                # byte offsets
 â”ƒ â”— ðŸ“œts                   # lidar timestamps (10Hz)
 â”£ ðŸ“‚radar
 â”ƒ â”£ ðŸ“œiq                   # raw complex time signal
 â”ƒ â”£ ðŸ“œmeta.json
 â”ƒ â”£ ðŸ“œradar.json           # radar intrinsics
 â”ƒ â”£ ðŸ“œts                   # radar timestamps (20Hz)
 â”ƒ â”— ðŸ“œvalid                # whether frames contain zero-filled dropped packets
 â”— ðŸ“œconfig.yaml            # original data collection configuration
```

??? info "Semantic Segmentation Classes"

    | 0 | 1 | 2 | 3 |
    |---|---|---|---|
    | flat | nature | sky | structure |

    | 4 | 5 | 6 | 7 |
    |---|---|---|---|
    | ceiling | object | person | vehicle |

    For full details about the class definitions, see the [class mapping](https://github.com/RadarML/red-rover/blob/main/processing/models/segformer-b5-finetuned-ade-640-640/classes.yaml) and [original ADE20k dataset](https://groups.csail.mit.edu/vision/datasets/ADE20K/).
